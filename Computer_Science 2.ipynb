{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b72b6122-3850-4e82-a67f-a6d9fa7edb2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved JSON: json_data/ACTIVITY_LOG.json\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import tkinter as tk\n",
    "from tkinter import ttk, filedialog, messagebox, StringVar, OptionMenu\n",
    "import os\n",
    "\n",
    "from matplotlib.backends.backend_tkagg import FigureCanvasTkAgg\n",
    "\n",
    "\n",
    "\n",
    "# -----------------------------------------------------------\n",
    "#                      GLOBAL VARIABLES\n",
    "# -----------------------------------------------------------\n",
    "MISSING_VALUES = [\"NA\", \"N/A\", \"na\", r\"^\\\\s*$\", \"\", \" \", \"NaN\"]\n",
    "\n",
    "#Tracking flags\n",
    "data_cleaned = False  # Tracks whether data cleaning has been performed\n",
    "\n",
    "# DataFrames for storing user inputs\n",
    "df_component_codes = None\n",
    "df_activity_log = None\n",
    "df_user_log = None\n",
    "df_cleaned_data = None\n",
    "\n",
    "#Pivot tables\n",
    "pivot_df = None # Aggregated by user, ignoring month\n",
    "monthly_pivot_df = None # Aggregated by user and month\n",
    "\n",
    "# Folder for storing JSON data\n",
    "JSON_FOLDER = \"json_data\"\n",
    "if not os.path.exists(JSON_FOLDER):\n",
    "    os.makedirs(JSON_FOLDER)\n",
    "\n",
    "#Full list of components\n",
    "all_csv_components = [\n",
    "    \"Assignment\", \"Quiz\", \"Lecture\", \"Book\", \"Project\", \"Course\", \"System\", \"Study_material\", \"Manual\", \"Folder\",\n",
    "    \"Page\", \"Questionnaire\", \"Feedback\", \"Attendence\", \"Source\", \"URL\", \"Test\", \"Survey\"\n",
    "                     ] \n",
    "\n",
    "# We remove System and Folder in clean_data().\n",
    "# We define componenets_of_interest \n",
    "components_of_interest = [\n",
    "    \"Assignment\", \"Quiz\", \"Lecture\", \"Attendence\", \"Survey\", \"Course\", \"Book\", \"Project\"\n",
    "]\n",
    "\n",
    "# Components for correlation analysis\n",
    "components_for_correlation = [\n",
    "    \"Assignment\", \"Quiz\", \"Lecture\", \"Book\", \"Project\", \"Course\"\n",
    "]\n",
    "\n",
    "# -----------------------------------------------------------\n",
    "#                   HELPER FUNCTIONS\n",
    "# -----------------------------------------------------------\n",
    "\n",
    "def convert_csv_to_json():\n",
    "    \"\"\"\n",
    "    Convert selected CSVs to JSON and save in JSON_FOLDER\n",
    "    \"\"\"\n",
    "    try:\n",
    "        filepaths = filedialog.askopenfilenames(\n",
    "            title=\"Select CSV files for conversion to JSON\",\n",
    "            filetypes=[(\"CSV Files\",\"*.csv\")]\n",
    "        )\n",
    "        if not filepaths:\n",
    "            messagebox.showinfo(\"Info\", \"No CSV files selected.\")\n",
    "            return\n",
    "\n",
    "        for fp in filepaths:\n",
    "            filename = os.path.basename(fp)\n",
    "            base_name = os.path.splitext(filename)[0]\n",
    "            df = pd.read_csv(fp)\n",
    "            json_path = os.path.join(JSON_FOLDER, f\"{base_name}.json\")\n",
    "            df.to_json(json_path, orient='records')\n",
    "            print(f\"Saved JSON: {json_path}\")\n",
    "\n",
    "        messagebox.showinfo(\"Success\", f\"Converted {len(filepaths)} file(s) to JSON.\")\n",
    "    except Exception as e:\n",
    "        messagebox.showerror(\"Error\", f\"Failed to convert CSV to JSON: {e}\")\n",
    "\n",
    "def load_data_from_json():\n",
    "    \"\"\"\n",
    "    Load saved JSON files (component_codes.json, activity_log.json, user_log,json) and store them in the global DataFrames.\n",
    "    \"\"\"\n",
    "    global df_component_codes, df_activity_log, df_user_log\n",
    "    try:\n",
    "        component_path = os.path.join(JSON_FOLDER, \"component_codes.json\")\n",
    "        activity_path = os.path.join(JSON_FOLDER, \"activity_log.json\")\n",
    "        user_path = os.path.join(JSON_FOLDER, \"user_log.json\")\n",
    "\n",
    "        df_component_codes = pd.read_json(component_path, orient='records')\n",
    "        df_activity_log = pd.read_json(activity_path, orient='records')\n",
    "        df_user_log = pd.read_json(user_path, orient='records')\n",
    "\n",
    "        messagebox.showinfo(\"Success\", \"JSON data loaded successfully.\")\n",
    "    except Exception as e:\n",
    "        messagebox.showerror(\"Error\", f\"Failed to load JSON data: {e}\")\n",
    "\n",
    "def clean_data():\n",
    "    \"\"\"\n",
    "    - REMOVE 'System and 'Folder\n",
    "    - RENAME 'User Full Name *Anonymized' to User_ID\n",
    "    - MERGE Suitable CSVs for analysing user interactions with each componenet\n",
    "    - RESHAPE: Reshape the data using the pivot operation - pivot_df (semester_ and monthyl_pivot_df (monthly_\n",
    "    _ COUNT: The interactions for each user with the componenet for each month\n",
    "    \"\"\"\n",
    "    global data_cleaned, df_cleaned_data\n",
    "    global pivot_df, monthly_pivot_df\n",
    "    global df_user_log, df_activity_log, df_component_codes\n",
    "    \n",
    "    try:\n",
    "        if df_component_codes is None:\n",
    "            messagebox.showwarning(\"Warning\", \"Please upload Component Codes first.\")\n",
    "            return\n",
    "        if df_activity_log is None:\n",
    "            messagebox.showwarning(\"Warning\", \"Please upload Activity Log first.\")\n",
    "            return\n",
    "        if df_user_log is None:\n",
    "            messagebox.showwarning(\"Warning\", \"Please upload User Log first.\")\n",
    "            return\n",
    "            \n",
    "\n",
    "        # Step 1. REMOVE: Filter out 'System' and 'Folder' components, and make a copy\n",
    "        df_activity_log_removed = df_activity_log[~df_activity_log['Component'].isin(['System', 'Folder'])].copy()\n",
    "\n",
    "        # Step 2. RENAME: 'User Full Name *Anonymized' to User_ID\n",
    "        df_user_log.rename(columns={\"User Full Name *Anonymized\": \"User_ID\"}, inplace=True)\n",
    "        df_activity_log_removed.rename(columns={\"User Full Name *Anonymized\": \"User_ID\"}, inplace=True)\n",
    "\n",
    "        # Step 3. MERGE\n",
    "        merged_df = pd.merge(df_activity_log_removed, df_user_log, on=\"User_ID\", how=\"left\")\n",
    "        merged_df = pd.merge(merged_df, df_component_codes, on=\"Component\", how=\"left\")\n",
    "\n",
    "        # Convert the Date to datetime and extract Month\n",
    "        merged_df[\"Date\"] = pd.to_datetime(merged_df[\"Date\"], errors=\"coerce\")\n",
    "        merged_df[\"Month\"] = merged_df[\"Date\"].dt.month\n",
    "\n",
    "        # Step 4 & 5: Rehape and Count\n",
    "        # Group by (User_id, Componenet, Mon th), and then count the interactions\n",
    "        grouped = merged_df.groupby([\"User_ID\", \"Component\", \"Month\"]).size().reset_index(name=\"Interaction_Count\")\n",
    "\n",
    "        #a) pinvot_df (entire semester): sums up across all months\n",
    "        global_pivot = grouped.groupby([\"User_ID\", \"Component\"])[\"Interaction_Count\"].sum().reset_index()\n",
    "        pivot_df = global_pivot.pivot_table(\n",
    "            index=\"User_ID\",\n",
    "            columns=\"Component\",\n",
    "            values=\"Interaction_Count\",\n",
    "            fill_value=0,\n",
    "            aggfunc=\"sum\"\n",
    "        )\n",
    "\n",
    "        #b) monthly_pivot_df: preserve the (User_ID, Month) index\n",
    "        monthly_pivot_df = grouped.pivot_table(\n",
    "            index=[\"User_ID\", \"Month\"],\n",
    "            columns=\"Component\",\n",
    "            values=\"Interaction_Count\",\n",
    "            fill_value=0,\n",
    "            aggfunc=\"sum\"\n",
    "        )\n",
    "\n",
    "        df_cleaned_data = merged_df\n",
    "        data_cleaned = True\n",
    "        messagebox.showinfo(\"Success\", \"Data cleaned and pivoted successfully!\")\n",
    "\n",
    "    except Exception as e:\n",
    "        messagebox.showerror(\"Error\", f\"Error cleaning data: {e}\")\n",
    "\n",
    "def compute_statistics(component):\n",
    "    \"\"\"\n",
    "    Compute mean, median, mode across the entire semester (in pivot_df) for entire semester.\n",
    "    \"\"\"\n",
    "    if pivot_df is None:\n",
    "        raise ValueError(\"pivot_df is empty. Clean your data first.\")\n",
    "    if component not in pivot_df.columns:\n",
    "        raise ValueError(f\"Component '{component}' not found in pivot_df.\")\n",
    "\n",
    "    data = pivot_df[component]\n",
    "    mean_val = data.mean()\n",
    "    median_val = data.median()\n",
    "    \n",
    "    mode_series = data.mode()\n",
    "    if not mode_series.empty:\n",
    "        mode_val = mode_series.iloc[0]\n",
    "    else:\n",
    "        mode_val = None\n",
    "\n",
    "    return {\n",
    "        \"mean\": mean_val,\n",
    "        \"median\": median_val,\n",
    "        \"mode\": mode_val\n",
    "\n",
    "    }\n",
    "\n",
    "def show_statistics():\n",
    "    \"\"\"\n",
    "    GUI callback: Show entire-semester stats for a selected component.\n",
    "    \"\"\"\n",
    "    if pivot_df is None:\n",
    "        messagebox.showerror(\"Error\", \"No data available. Please upload and clean first.\")\n",
    "        return\n",
    "    comp = selected_component.get()\n",
    "    try:\n",
    "        stats = compute_statistics(comp)\n",
    "        out = (\n",
    "            f\"Component: {comp}\\n\"\n",
    "            f\"Mean: {stats['mean']:.2f}\\n\"\n",
    "            f\"Median: {stats['median']:.2f}\\n\"\n",
    "            f\"Mode: {stats['mode']}\"\n",
    "        )\n",
    "        stats_label.config(text=out)\n",
    "    except Exception as e:\n",
    "        messagebox.showerror(\"Uh-oh, error\", str(e))\n",
    "        \n",
    "def compute_monthly_statistics(component):\n",
    "    \"\"\"\n",
    "    Compute monthly mean, median, mode for the given component (monthly_pivot_df).\n",
    "    Returns a dict keyed by month -> {mean, median, mode}.\n",
    "    \"\"\"\n",
    "    if monthly_pivot_df is None:\n",
    "        raise ValueError(\"The monthly_pivot_df is empty. Can you please clean your data first?\")\n",
    "    if component not in monthly_pivot_df.columns:\n",
    "        raise ValueError(f\"Uh-oh Component '{component}' is not found in monthly_pivot_df.\")\n",
    "\n",
    "    monthly_stats = {}\n",
    "    # monthly_pivot_df is indexed by (User_ID, Month) => group by 'Month' level\n",
    "    for month_val, data in monthly_pivot_df[component].groupby(level=\"Month\"):\n",
    "        mmean = data.mean()\n",
    "        mmedian = data.median()\n",
    "        mmode_series = data.mode()\n",
    "        mmode = mmode_series.iloc[0] if not mmode_series.empty else None\n",
    "        monthly_stats[month_val] = {\"mean\": mmean, \"median\": mmedian, \"mode\": mmode}\n",
    "\n",
    "    return monthly_stats\n",
    "    \n",
    "def show_monthly_statistics():\n",
    "    \"\"\"\n",
    "    GUI callback: Show monthly stats for selected component.\n",
    "    \"\"\"\n",
    "    if not data_cleaned:\n",
    "        messagebox.showwarning(\"Warning\", \"Please clean data before computing monthly stats.\")\n",
    "        return\n",
    "\n",
    "    comp = selected_component.get()\n",
    "    try:\n",
    "        mstats = compute_monthly_statistics(comp)\n",
    "        lines = []\n",
    "        for month_val in sorted(mstats.keys()):\n",
    "            lines.append(\n",
    "                f\"Month {month_val}: Mean={mstats[month_val]['mean']:.2f}, \"\n",
    "                f\"Median={mstats[month_val]['median']:.2f}, \"\n",
    "                f\"Mode={mstats[month_val]['mode']}\"\n",
    "            )\n",
    "        monthly_stats_label.config(text=\"\\n\".join(lines))\n",
    "    except Exception as e:\n",
    "        messagebox.showerror(\"Uh-oh, error\", str(e))\n",
    "\n",
    "def compute_semester_statistics():\n",
    "    \"\"\"\n",
    "    Show entire-semester stats (mean, median, mode) for each of\n",
    "    the 'components_of_interest' in pivot_df.\n",
    "    \"\"\"\n",
    "    if pivot_df is None:\n",
    "        messagebox.showerror(\"Error\", \"No pivot_df found. Please clean data first.\")\n",
    "        return\n",
    "        \n",
    "    lines = []\n",
    "    for comp in components_of_interest:\n",
    "        if comp in pivot_df.columns:\n",
    "            stats = compute_statistics(comp)\n",
    "            lines.append(\n",
    "                f\"{comp}: Mean={stats['mean']:.2f}, \"\n",
    "                f\"Median={stats['median']:.2f}, Mode={stats['mode']}\"\n",
    "            )\n",
    "\n",
    "    if lines:\n",
    "        semester_stats_label.config(text=\"\\n\".join(lines))\n",
    "    else:\n",
    "        semester_stats_label.config(text=\" There is no valid components found in pivot_df.\")\n",
    "\n",
    "\n",
    "def generate_graph():\n",
    "    \"\"\"\n",
    "    Generate a heatmap showing correlation for the components_for_correlation\n",
    "    in pivot_df (entire semester).\n",
    "    \"\"\"\n",
    "    if pivot_df is None:\n",
    "        messagebox.showerror(\"Error\", \"No data to analyse. Please clean data first.\")\n",
    "        return\n",
    "\n",
    "  # Filter only the components we want AND which actually exist\n",
    "    existing_cols = [c for c in components_for_correlation if c in pivot_df.columns]\n",
    "    if not existing_cols:\n",
    "        messagebox.showerror(\"Error\", \"No data to analyse. Please clean data first.\")\n",
    "        return\n",
    "        \n",
    "  # Calculate correlation\n",
    "    selected_data = pivot_df[existing_cols]\n",
    "    corr_matrix = selected_data.corr()\n",
    "\n",
    " # Clear any existing graph from the frame first\n",
    "    for widget in graph_frame.winfo_children():\n",
    "        widget.destroy()\n",
    "\n",
    "  # Create a figure for the heatmap\n",
    "    fig = plt.Figure(figsize=(7, 5), dpi=100)\n",
    "    ax = fig.add_subplot(111)\n",
    "    sns.heatmap(corr_matrix, ax=ax, annot=True, cmap=\"coolwarm\", square=True)\n",
    "    ax.set_title(\"Correlation Heatmap\")\n",
    "    fig.tight_layout()\n",
    "\n",
    "  # Embed the figure in the graph_frame\n",
    "    canvas = FigureCanvasTkAgg(fig, master=graph_frame)\n",
    "    canvas.draw()\n",
    "    canvas.get_tk_widget().pack(side=\"top\", fill=\"both\", expand=True)\n",
    "\n",
    "\n",
    "def save_prepared_data():\n",
    "    \"\"\"\n",
    "    Save df_cleaned_data (the merged DataFrame) to CSV or JSON.\n",
    "    \"\"\"\n",
    "    if df_cleaned_data is None or pivot_df is None:\n",
    "        messagebox.showerror(\"Error\", \"No cleaned data available to save.\")\n",
    "        return\n",
    "    try:\n",
    "        file_path = filedialog.asksaveasfilename(\n",
    "            defaultextension=\".csv\",\n",
    "            filetypes=[(\"CSV Files\", \"*.csv\"), (\"JSON Files\", \"*.json\")],\n",
    "        )\n",
    "        if not file_path:\n",
    "            return\n",
    "\n",
    "        if file_path.endswith(\".csv\"):\n",
    "            df_cleaned_data.to_csv(file_path, index=False)\n",
    "        elif file_path.endswith(\".json\"):\n",
    "            df_cleaned_data.to_json(file_path, orient='records')\n",
    "\n",
    "        messagebox.showinfo(\"Success\", f\"Saved prepared data to {file_path}\")\n",
    "    except Exception as e:\n",
    "        messagebox.showerror(\"Error\", f\"Error saving data: {e}\")\n",
    "\n",
    "# -----------------------------------------------------------\n",
    "#                  TKINTER WINDOW SETUP\n",
    "# -----------------------------------------------------------\n",
    "window = tk.Tk()\n",
    "window.title(\"Analysis Tool\")\n",
    "window.geometry(\"900x650\")\n",
    "window.resizable(False, False)\n",
    "\n",
    "# Notebook tabs\n",
    "notebook = ttk.Notebook(window)\n",
    "tab_upload = ttk.Frame(notebook)\n",
    "tab_clean = ttk.Frame(notebook)\n",
    "tab_analysis = ttk.Frame(notebook)\n",
    "\n",
    "notebook.add(tab_upload, text=\"Step 1. Upload Data\")\n",
    "notebook.add(tab_clean, text=\"Step 2. Clean Data & Prepare your Data\")\n",
    "notebook.add(tab_analysis, text=\"Step 3. Analyse Data\")\n",
    "notebook.pack(expand=1, fill=\"both\")\n",
    "\n",
    "# -----------------------------------------------------------\n",
    "#                      UPLOAD FUNCTIONS\n",
    "# -----------------------------------------------------------\n",
    "\n",
    "#Upload Tab 1\n",
    "ttk.Label(tab_upload, text=\"Step 1: Upload CSV Files\").pack(pady=5)\n",
    "\n",
    "\n",
    "def upload_component_codes():\n",
    "    global df_component_codes\n",
    "    path = filedialog.askopenfilename(filetypes=[(\"CSV Files\", \"*.csv\")])\n",
    "    if not path:\n",
    "        return\n",
    "    try:\n",
    "        df_component_codes = pd.read_csv(path, keep_default_na=False, na_values=MISSING_VALUES)\n",
    "        messagebox.showinfo(\"Success\", \"Component Codes uploaded successfully!\")\n",
    "    except Exception as ex:\n",
    "        messagebox.showerror(\"Error\", f\"Error loading Component Codes: {ex}\")\n",
    "\n",
    "def upload_activity_log():\n",
    "    global df_activity_log\n",
    "    path = filedialog.askopenfilename(filetypes=[(\"CSV Files\", \"*.csv\")])\n",
    "    if not path:\n",
    "        return\n",
    "    try:\n",
    "        df_activity_log = pd.read_csv(path, keep_default_na=False, na_values=MISSING_VALUES)\n",
    "        messagebox.showinfo(\"Success\", \"Activity Log uploaded successfully!\")\n",
    "    except Exception as ex:\n",
    "        messagebox.showerror(\"Error\", f\"Error loading Activity Log: {ex}\")\n",
    "\n",
    "\n",
    "def upload_user_log():\n",
    "    global df_user_log\n",
    "    path = filedialog.askopenfilename(filetypes=[(\"CSV Files\", \"*.csv\")])\n",
    "    if not path:\n",
    "        return\n",
    "    try:\n",
    "        df_user_log = pd.read_csv(path, keep_default_na=False, na_values=MISSING_VALUES)\n",
    "        messagebox.showinfo(\"Success\", \"User Log uploaded successfully!\")\n",
    "    except Exception as ex:\n",
    "        messagebox.showerror(\"Error\", f\"Error loading User Log: {ex}\")\n",
    "\n",
    "# Upload Buttons\n",
    "btn_upload_component = ttk.Button(tab_upload, text=\"Upload Component Codes\", command=upload_component_codes)\n",
    "btn_upload_activity = ttk.Button(tab_upload, text=\"Upload Activity Log\", command=upload_activity_log)\n",
    "btn_upload_user = ttk.Button(tab_upload, text=\"Upload User Log\", command=upload_user_log)\n",
    "\n",
    "btn_upload_component.pack(pady=5)\n",
    "btn_upload_activity.pack(pady=5)\n",
    "btn_upload_user.pack(pady=5)\n",
    "\n",
    "# Convert CSV to JSON\n",
    "ttk.Label(tab_upload, text=\"Convert CSV to JSON\").pack(pady=10)\n",
    "btn_convert_to_json = ttk.Button(tab_upload, text=\"Convert CSV to JSON\", command=convert_csv_to_json)\n",
    "btn_convert_to_json.pack(pady=5)\n",
    "\n",
    "# Load from JSON\n",
    "ttk.Label(tab_upload, text=\"Load from previously converted JSON\").pack(pady=10)\n",
    "btn_load_json = ttk.Button(tab_upload, text=\"Load Data from JSON\", command=load_data_from_json)\n",
    "btn_load_json.pack(pady=5)\n",
    "\n",
    "# -----------------------------------------------------------\n",
    "#                      CLEAN FUNCTIONS\n",
    "# -----------------------------------------------------------\n",
    "#Clean Tab 2\n",
    "ttk.Label(tab_clean, text=\"Step 2: Clean & Prepare Data\").pack(pady=10)\n",
    "btn_clean_data = ttk.Button(tab_clean, text=\"Clean Data\", command=clean_data)\n",
    "btn_clean_data.pack(pady=10)\n",
    "\n",
    "# -----------------------------------------------------------\n",
    "#                   ANALYSIS FUNCTIONS\n",
    "# -----------------------------------------------------------\n",
    "#Analysis Tab 3\n",
    "\n",
    "# Scrollable canvas in tab_analysis, then place frames inside it\n",
    "analysis_canvas = tk.Canvas(tab_analysis)\n",
    "analysis_scrollbar = ttk.Scrollbar(tab_analysis, orient=\"vertical\", command=analysis_canvas.yview)\n",
    "analysis_frame = ttk.Frame(analysis_canvas)\n",
    "\n",
    "analysis_frame.bind(\n",
    "    \"<Configure>\",\n",
    "    lambda e: analysis_canvas.configure(scrollregion=analysis_canvas.bbox(\"all\"))\n",
    ")\n",
    "\n",
    "analysis_canvas.create_window((0, 0), window=analysis_frame, anchor=\"nw\")\n",
    "\n",
    "analysis_canvas.configure(yscrollcommand=analysis_scrollbar.set)\n",
    "analysis_canvas.pack(side=\"left\", fill=\"both\", expand=True)\n",
    "analysis_scrollbar.pack(side=\"right\", fill=\"y\")\n",
    "\n",
    "# 1) Single-Component Stats (Entire Semester)\n",
    "single_stats_frame = ttk.LabelFrame(analysis_frame, text=\"Single-Component Stats (Entire Semester)\")\n",
    "single_stats_frame.pack(fill=\"x\", pady=10, padx=10)\n",
    "\n",
    "selected_component = tk.StringVar()\n",
    "selected_component.set(components_of_interest[0])  # default\n",
    "\n",
    "ttk.Label(single_stats_frame, text=\"Select Component:\").pack(side=\"left\", padx=5)\n",
    "comp_menu = ttk.OptionMenu(single_stats_frame, selected_component, components_of_interest[0], *components_of_interest)\n",
    "comp_menu.pack(side=\"left\", padx=5)\n",
    "\n",
    "stats_button = ttk.Button(single_stats_frame, text=\"Get Stats\", command=show_statistics)\n",
    "stats_button.pack(side=\"left\", padx=5)\n",
    "\n",
    "stats_label = tk.Label(single_stats_frame, text=\"\", justify=\"left\")\n",
    "stats_label.pack(side=\"left\", padx=15)\n",
    "\n",
    "\n",
    "# 2) Monthly Stats\n",
    "monthly_frame = ttk.LabelFrame(analysis_frame, text=\"Monthly Stats for Selected Component\")\n",
    "monthly_frame.pack(fill=\"x\", pady=10, padx=10)\n",
    "\n",
    "monthly_button = ttk.Button(monthly_frame, text=\"Get Monthly Stats\", command=show_monthly_statistics)\n",
    "monthly_button.pack(side=\"left\", padx=5)\n",
    "\n",
    "monthly_stats_label = tk.Label(monthly_frame, text=\"\", justify=\"left\")\n",
    "monthly_stats_label.pack(side=\"left\", padx=15)\n",
    "\n",
    "# 3) Entire-Semester Stats (All interest components)\n",
    "semester_frame = ttk.LabelFrame(analysis_frame, text=\"Entire-Semester Stats (All Components of Interest)\")\n",
    "semester_frame.pack(fill=\"x\", pady=10, padx=10)\n",
    "\n",
    "semester_stats_button = ttk.Button(semester_frame, text=\"Get Semester Stats\", command=compute_semester_statistics)\n",
    "semester_stats_button.pack(side=\"left\", padx=5)\n",
    "\n",
    "semester_stats_label = tk.Label(semester_frame, text=\"\", justify=\"left\")\n",
    "semester_stats_label.pack(side=\"left\", padx=15)\n",
    "\n",
    "# 4) Correlation Heatmap\n",
    "graph_frame = ttk.LabelFrame(analysis_frame, text=\"Correlation Heatmap\")\n",
    "graph_frame.pack(fill=\"both\", pady=10, padx=10)\n",
    "\n",
    "graph_button = ttk.Button(graph_frame, text=\"Generate Correlation Graph\", command=generate_graph)\n",
    "graph_button.pack(side=\"top\", padx=5, pady=5)\n",
    "\n",
    "# 5) Save Data\n",
    "save_data_frame = ttk.LabelFrame(analysis_frame, text=\"Save Merged/Cleaned Data\")\n",
    "save_data_frame.pack(fill=\"x\", pady=10, padx=10)\n",
    "\n",
    "btn_save_data = ttk.Button(save_data_frame, text=\"Save Prepared Data\", command=save_prepared_data)\n",
    "btn_save_data.pack(side=\"left\", padx=5)\n",
    "\n",
    "# -----------------------------------------------------------\n",
    "#               MAINLOOP\n",
    "# -----------------------------------------------------------\n",
    "window.mainloop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79483861-799f-4481-9bee-dc9d422ecc96",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
